<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <script type="text/javascript" src="js/hidebib.js"></script>
  <title>Ran Tao</title>

  <meta name="author" content="Ran Tao">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Ran Tao</name>
              </p>
              <p>
                I am a Ph.D. student at University of Illinois Urbana Champaign advised by <a href="https://scholar.google.com/citations?hl=en&user=8mA9QpUAAAAJ">Prof. Naira Hovakimyan</a>.
                My research interests include adatpive control, model predictive control, optimization, and machine learning for autonomous vehicles.
                I received my Bachlor of Science at UIUC in May 2021 and the Master of Science at UIUC in December 2022.
              </p>
              <p style="text-align:center">
                <a href="mailto:rant3@illinois.edu">Email</a>  &nbsp/&nbsp
                <a href="files/Ran_Tao_Resume.pdf">Resume</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=E8ZS0SkAAAAJ&hl=en">Google Scholar</a>
                <!-- <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp
                <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=jktWnL8AAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/jonbarron/">Github</a> -->
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:80%;max-width:100%" alt="profile photo" src="images/icon.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <!-- Published Papers -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Published Papers</heading>
              <!-- <p>
                I'm interested in computer vision, machine learning, optimization, and image processing. Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images. Representative papers are <span class="highlight">highlighted</span>.
              </p> -->
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


            <tr>
              <!-- <td width="40%" valign="top" align="center"><a>
                <img src="images/backupplan.png" alt="sym" width="80%" style="margin-top:15px;padding-top:0px;padding-bottom:0px;border-radius:15px;"></video> -->
              <td width="60%" valign="top">
                <papertitle style="font-size:20px;">Backup Plan Constrained Model Predictive Control with Guaranteed Stability</papertitle></a><br>
                <b>Ran Tao</b>, Hunmin Kim, Hyung-Jin Yoon, Wenbin WanNaira Hovakimyan, Lui Sha, Petros Voulgaris
                <br/> AIAA Journal of Guidance, Control, and Dynamics, 47(2), 233-246.
                </p>
                <div class="paper" id="bakcupplan">
                <a href="https://arxiv.org/abs/2306.06102">arXiv</a> |
                <a href="javascript:toggleblock('backupplan_abs')">abstract</a> |
                <!-- < <a shape="rect" href="javascript:togglebib('backupplan_bib')" class="togglebib">bibtex</a> | -->
                <p align="justify"> <i id="backupplan_abs"> This article proposes and evaluates a new safety concept called backup plan safety for path planning of autonomous vehicles under mission uncertainty. Backup plan safety is defined as the ability to complete an alternative mission when the primary mission is aborted. To include this new safety concept in control problems, we formulate a feasibility maximization problem aiming to maximize the feasibility of the primary and alternative missions. The feasibility maximization problem is based on multi-objective model predictive control (MPC), where each objective (cost function) is associated with a different mission and balanced by a weight vector. Furthermore, the feasibility maximization problem incorporates additional control input horizons toward the alternative missions on top of the control input horizon toward the primary mission, denoted as multi-horizon inputs, to evaluate the cost for each mission. We develop the backup plan constrained MPC algorithm, which designs the weight vector that ensures asymptotic stability of the closed-loop system, and generates the optimal control input by solving the feasibility maximization problem with computational efficiency. The performance of the proposed algorithm is validated through simulations of a UAV path planning problem.
                <small><i id="backupplan_bib"><pre xml:space="preserve">
                  @article{tao2023backup,
        title={Backup Plan Constrained Model Predictive Control with Guaranteed Stability},
        author={Tao, Ran and Kim, Hunmin and Yoon, Hyung-Jin and Wan, Wenbin and Hovakimyan, Naira and Sha, Lui and Voulgaris, Petros},
        journal={AIAA Journal of Guidance, Control, and Dynamics},
        year={2023}
      }
            </pre></i></small>
              </div>
              </td>
              </tr>


              <tr>
              <!-- <td width="33%" valign="top" align="center"><a >
              <img src="images/ARMPC.jpg" alt="sym" width="90%" style="margin-top:15px;padding-top:0px;padding-bottom:0px;border-radius:15px;"></video> -->
                    <!-- <img src="images/rma.gif" alt="sym" width="90%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;"> -->
              </a></td>
              <td width="67%" valign="top">
                <!-- <p><a href="https://github.com/microsoft/EdgeML" id="FASTGRNN"> -->
                <!-- <img src="images/new.png" alt="[NEW]" width="6%" style="border-style: none"> -->
                <papertitle style="font-size:20px;">Robust Adaptive MPC Using Uncertainty Compensation</papertitle></a><br>
                <b>Ran Tao</b>, Pan Zhao, Ilya Kolmanovsky, and Naira Hovakimyan<br>
                In 2024 American Control Conference (ACC), pp. 1873-1878. IEEE, 2024.
                </p>

                <div class="paper" id="ARMPC">
                <!-- <a href="files/cooling.pdf">PDF</a> | -->
                <a href="https://arxiv.org/abs/2309.13743">arXiv</a> |
                <a href="javascript:toggleblock('ARMPC_abs')">abstract</a> |
                <!-- < <a shape="rect" href="javascript:togglebib('cooling_bib')" class="togglebib">bibtex</a> | -->
                <p align="justify"> <i id="ARMPC_abs"> This paper presents an uncertainty compensationbased robust adaptive model predictive control (MPC) framework for linear systems with both matched and unmatched nonlinear uncertainties subject to both state and input constraints. L1 adaptive controller (L1AC) to compensate for the matched uncertainties and to provide guaranteed uniform bounds on the error between the states and control inputs of the actual system and those of a nominal i.e., uncertainty-free, system. The performance bounds provided by the L1AC are then used to tighten the state and control constraints of the actual system, and a model predictive controller is designed for the nominal system with the tightened constraints. The proposed control framework, which we denote as uncertainty compensationbased MPC (UC-MPC), guarantees constraint satisfaction and achieves improved performance compared with existing methods. Simulation results on a flight control example demonstrate the benefits of the proposed framework.

                  </i></p>
                  <small><i id="ARMPC_bib"><pre xml:space="preserve">
                    @article{tao2023robust,
                      title={Robust Adaptive MPC Using Uncertainty Compensation},
                      author={Tao, Ran and Zhao, Pan and Kolmanovsky, Ilya and Hovakimyan, Naira},
                      journal={arXiv preprint arXiv:2309.13743},
                      year={2023}
                    }
              </pre>
              </div>
              </td>
              </tr>




              <tr>
              <!-- <td width="33%" valign="top" align="center"><a >
              <img src="images/DIFFTUNE.jpg" alt="sym" width="90%" style="margin-top:15px;padding-top:0px;padding-bottom:0px;border-radius:15px;"></video> -->
                    <!-- <img src="images/rma.gif" alt="sym" width="90%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;"> -->
              </a></td>
              <td width="67%" valign="top">
                <!-- <p><a href="https://github.com/microsoft/EdgeML" id="FASTGRNN"> -->
                <!-- <img src="images/new.png" alt="[NEW]" width="6%" style="border-style: none"> -->
                <papertitle style="font-size:20px;">DiffTune-MPC: Closed-Loop Learning for Model Predictive Control</papertitle></a><br>
                <b>Ran Tao</b>, Sheng Cheng, Xiaofeng Wang, Shenlong Wang, Naira Hovakimyan<br>
                IEEE Robotics and Automation Letters (2024).
                </p>

                <div class="paper" id="ARMPC">
                <!-- <a href="files/cooling.pdf">PDF</a> | -->
                <a href="https://arxiv.org/abs/2312.11384">arXiv</a> |
                <a href="javascript:toggleblock('DIFFTUNE_abs')">abstract</a> |
                <!-- < <a shape="rect" href="javascript:togglebib('cooling_bib')" class="togglebib">bibtex</a> | -->
                <p align="justify"> <i id="DIFFTUNE_abs"> Model predictive control (MPC) has been applied to many platforms in robotics and autonomous systems for its capability to predict a system's future behavior while incorporating constraints that a system may have. To enhance the performance of a system with an MPC controller, one can manually tune the MPC's cost function. However, it can be challenging due to the possibly high dimension of the parameter space as well as the potential difference between the open-loop cost function in MPC and the overall closed-loop performance metric function. This paper presents DiffTune-MPC, a novel learning method, to learn the cost function of an MPC in a closed-loop manner. The proposed framework is compatible with the scenario where the time interval for performance evaluation and MPC's planning horizon have different lengths. We show the auxiliary problem whose solution admits the analytical gradients of MPC and discuss its variations in different MPC settings. Simulation results demonstrate the capability of DiffTune-MPC and illustrate the influence of constraints (from actuation limits) on learning.

                  </i></p>
                  <small><i id="DIFFTUNE_bib"><pre xml:space="preserve">
                    @article{tao2023difftune,
                      title={DiffTune-MPC: Closed-Loop Learning for Model Predictive Control},
                      author={Tao, Ran and Cheng, Sheng and Wang, Xiaofeng and Wang, Shenlong and Hovakimyan, Naira},
                      journal={arXiv preprint arXiv:2312.11384},
                      year={2023}
                    }
              </pre>
              </div>
              </td>
              </tr>

              <tr>
                <!-- <td width="40%" valign="top" align="center"><a>
                  <img src="images/f1.jpg" alt="sym" width="80%" style="margin-top:15px;padding-top:0px;padding-bottom:0px;border-radius:15px;"></video> -->
             <!-- <img src="images/rma.gif" alt="sym" width="90%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;"> -->
       </a></td>
                <td width="100%" valign="top">
                  <papertitle style="font-size:20px;">Optimizing Nitrogen Management with Deep Reinforcement Learning and Crop Simulations</papertitle></a><br>
                  Jing Wu, <b>Ran Tao</b>, Pan Zhao, Nicolas F. Martin, Naira Hovakimyan
                  <br/>In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, 2022, pp. 1712-1720
                  </p>
                  <div class="paper" id="RL1">
                  <a href="https://arxiv.org/abs/2204.10394">arXiv</a> |
                  <a href="javascript:toggleblock('RL1_abs')">abstract</a> |
                  <!-- <a shape="rect" href="javascript:togglebib('RL1_bib')" class="togglebib">bibtex</a> | -->
                  <p align="justify"> <i id="RL1_abs"> Nitrogen (N) management is critical to sustain soil fertility and crop production while minimizing the negative environmental impact, but is challenging to optimize. This paper proposes an intelligent N management system using deep reinforcement learning (RL) and crop simulations with Decision Support System for Agrotechnology Transfer (DSSAT). We first formulate the N management problem as an RL problem. We then train management policies with deep Q-network and soft actor-critic algorithms, and the Gym-DSSAT interface that allows for daily interactions between the simulated crop environment and RL agents. According to the experiments on the maize crop in both Iowa and Florida in the US, our RL-trained policies outperform previous empirical methods by achieving higher or similar yield while using less fertilizers.
                  </i></p>
                  <small><i id="RL1_bib"><pre xml:space="preserve">
    @inproceedings{wu2022optimizing,
    title={Optimizing Nitrogen Management with Deep Reinforcement Learning and Crop Simulations},
    author={Wu, Jing and Tao, Ran and Zhao, Pan and Martin, Nicolas F and Hovakimyan, Naira},
    booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    pages={1712--1720},
    year={2022}
    }
       </pre></i></small>
              </div>
              </td>
              </tr>
    
    
    
              <tr>
                <!-- <td width="40%" valign="top" align="center"><a>
                  <img src="images/f2.jpg" alt="sym" width="80%" style="margin-top:15px;padding-top:0px;padding-bottom:0px;border-radius:15px;"></video> -->
                <td width="100%" valign="top">
                  <papertitle style="font-size:20px;">Optimizing Crop Management with Reinforcement Learning and Imitation Learning</papertitle></a><br>
                  <b>Ran Tao</b>, Pan Zhao, Jing Wu, Nicolas F. Martin, Matthew T. Harrison, Carla Ferreira, Zahra Kalantari, Naira Hovakimyan
                  <br/> In Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence
    AI for Good. Pages 6228-6236. 
                  </p>
                  <div class="paper" id="RL2">
                  <a href="https://arxiv.org/abs/2209.09991">arXiv</a> |
                  <a href="javascript:toggleblock('RL2_abs')">abstract</a> |
                  <!-- < <a shape="rect" href="javascript:togglebib('RL2_bib')" class="togglebib">bibtex</a> | -->
                  <p align="justify"> <i id="RL2_abs"> Crop management, including nitrogen (N) fertilization and irrigation management, has a significant impact on the crop yield, economic profit, and the environment. Although management guidelines exist, it is challenging to find the optimal management practices given a specific planting environment and a crop. Previous work used reinforcement learning (RL) and crop simulators to solve the problem, but the trained policies either have limited performance or are not deployable in the real world. In this paper, we present an intelligent crop management system which optimizes the N fertilization and irrigation simultaneously via RL, imitation learning (IL), and crop simulations using the Decision Support System for Agrotechnology Transfer (DSSAT). We first use deep RL, in particular, deep Q-network, to train management policies that require all state information from the simulator as observations (denoted as full observation). We then invoke IL to train management policies that only need a limited amount of state information that can be readily obtained in the real world (denoted as partial observation) by mimicking the actions of the previously RL-trained policies under full observation. We conduct experiments on a case study using maize in Florida and compare trained policies with a maize management guideline in simulations. Our trained policies under both full and partial observations achieve better outcomes, resulting in a higher profit or a similar profit with a smaller environmental impact. Moreover, the partial-observation management policies are directly deployable in the real world as they use readily available information.
                  </i></p>
                  <small><i id="RL2_bib"><pre xml:space="preserve">
    @article{tao2022optimizing,
    title={Optimizing Crop Management with Reinforcement Learning and Imitation Learning},
    author={Tao, Ran and Zhao, Pan and Wu, Jing and Martin, Nicolas F and Harrison, Matthew T and Ferreira, Carla and Kalantari, Zahra and Hovakimyan, Naira},
    journal={arXiv preprint arXiv:2209.09991},
    year={2022}
    }
     </pre></i></small>
                </div>
                </td>
                </tr>



                <tr>
                  <!-- <td width="40%" valign="top" align="center"><a>
                    <img src="images/f2.jpg" alt="sym" width="80%" style="margin-top:15px;padding-top:0px;padding-bottom:0px;border-radius:15px;"></video> -->
                  <td width="100%" valign="top">
                    <papertitle style="font-size:20px;">The New Agronomists: Language Models are Experts in Crop Management</papertitle></a><br>
                    Jing Wu, Zhixin Lai, Suiyao Chen, <b>Ran Tao</b>, Pan Zhao, Naira Hovakimyan
                    <br/> In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, 2024, pp. 5346-5356
 
                    </p>
                    <div class="paper" id="RL3">
                    <a href="https://arxiv.org/abs/2403.19839">arXiv</a> |
                    <a href="javascript:toggleblock('RL3_abs')">abstract</a> |
                    <!-- < <a shape="rect" href="javascript:togglebib('RL3_bib')" class="togglebib">bibtex</a> | -->
                    <p align="justify"> <i id="RL3_abs"> Crop management plays a crucial role in determining crop yield, economic profitability, and environmental sustainability. Despite the availability of management guidelines, optimizing these practices remains a complex and multifaceted challenge. In response, previous studies have explored using reinforcement learning with crop simulators, typically employing simple neural-network-based reinforcement learning (RL) agents. Building on this foundation, this paper introduces a more advanced intelligent crop management system. This system uniquely combines RL, a language model (LM), and crop simulations facilitated by the Decision Support System for Agrotechnology Transfer (DSSAT). We utilize deep RL, specifically a deep Q-network, to train management policies that process numerous state variables from the simulator as observations. A novel aspect of our approach is the conversion of these state variables into more informative language, facilitating the language model's capacity to understand states and explore optimal management practices. The empirical results reveal that the LM exhibits superior learning capabilities. Through simulation experiments with maize crops in Florida (US) and Zaragoza (Spain), the LM not only achieves state-of-the-art performance under various evaluation metrics but also demonstrates a remarkable improvement of over 49\% in economic profit, coupled with reduced environmental impact when compared to baseline methods. 
                    </i></p>
                    <small><i id="RL3_bib"><pre xml:space="preserve">
                      @inproceedings{wu2024new,
                        title={The new agronomists: Language models are experts in crop management},
                        author={Wu, Jing and Lai, Zhixin and Chen, Suiyao and Tao, Ran and Zhao, Pan and Hovakimyan, Naira},
                        booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
                        pages={5346--5356},
                        year={2024}
                      }
       </pre></i></small>
                  </div>
                  </td>
                  </tr>

            <tr>
            <!-- <td width="33%" valign="top" align="center"><a >
            <img src="images/cooling.jpg" alt="sym" width="90%" style="margin-top:15px;padding-top:0px;padding-bottom:0px;border-radius:15px;"></video> -->
                  <!-- <img src="images/rma.gif" alt="sym" width="90%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;"> -->
            </a></td>
            <td width="67%" valign="top">
              <!-- <p><a href="https://github.com/microsoft/EdgeML" id="FASTGRNN"> -->
              <!-- <img src="images/new.png" alt="[NEW]" width="6%" style="border-style: none"> -->
              <papertitle style="font-size:20px;">Three-Dimensional Printable Nanoporous Polymer Matrix Composites for Daytime Radiative Cooling</papertitle></a><br>
              Kai Zhou, Wei Li, Bijal Bankim Patel, <b>Ran Tao</b>, Yilong Chang, Shanhui Fan, Ying Diao, and Lili Cai<br>
              Nano Letters 2021
              </p>

              <div class="paper" id="cooling">
              <!-- <a href="files/cooling.pdf">PDF</a> | -->
              <a href="https://pubs.acs.org/doi/10.1021/acs.nanolett.0c04810">Link</a> |
              <a href="javascript:toggleblock('cooling_abs')">abstract</a> |
              <!-- < <a shape="rect" href="javascript:togglebib('cooling_bib')" class="togglebib">bibtex</a> | -->
              <p align="justify"> <i id="cooling_abs"> Daytime radiative cooling presents an exciting new strategy for combating global warming, because it can passively cool buildings by reflecting sunlight and utilizing the infrared atmospheric window to eject heat into outer space. Recent progress with novel material designs showed promising subambient cooling performance under direct sunlight. However, large-scale implementation of radiative cooling technologies is still limited by the high-cost and complex fabrication. Here, we develop a nanoporous polymer matrix composite (PMC) to enable rapid production and cost reduction using commercially available polymer processing techniques, such as molding, extrusion, and 3D printing. With a high solar reflectance of 96.2% and infrared emissivity > 90%, the nanoporous PMC achieved a subambient temperature drop of 6.1 ¬∞C and cooling power of 85 W/m2 under direct sunlight, which are comparable to the state-of-the-art. This work offers great promise to make radiative cooling technologies more viable for saving energy and reducing emissions in building cooling applications.
                </i></p>
                <small><i id="cooling_bib"><pre xml:space="preserve">
@article{zhou2021three,
title={Three-dimensional printable nanoporous polymer matrix composites for daytime radiative cooling},
author={Zhou, Kai and Li, Wei and Patel, Bijal Bankim and Tao, Ran and Chang, Yilong and Fan, Shanhui and Diao, Ying and Cai, Lili},
journal={Nano letters},
volume={21},
number={3},
pages={1493--1499},
year={2021},
publisher={ACS Publications}
}
            </pre>
            </div>
            </td>
            </tr>
        </tbody></table>


        <!-- Internship Section -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Internship</heading>
            </td>
          </tr>
      </tbody></table>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
          <tr>
            <td width="100%" valign="top">
              <papertitle style="font-size:20px;">Motion Planning Intern, Zoox</papertitle></a><br>
              Foster City, California &nbsp; | &nbsp; May 2025 ‚Äì Aug 2025
              <ul>
                <li>Designed and implemented a context-aware stopping framework for autonomous urban driving, improving comfort and traffic interaction.</li>
                <li>Analyzed large-scale human driving datasets to extract behavioral features such as braking distance and deceleration patterns across intersections.</li>
                <li>Integrated human-inspired priors into an LQMT controller, aligning vehicle stopping behavior with human driving for smoother real-world performance.</li>
              </ul>
            </td>
          </tr>
        </tbody>
      </table>

        <!-- Personal Section -->      
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Personal</heading> <br> <br>

              <heading1>
                <a href="images/basketball.jpg">Basketball</a>, <a href="images/Fishing.jpg">Fishing</a>, <a href="images/snowboarding.jpg">Snowboarding</a>
              </heading1>

            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <!-- <tr>
            <td style="padding:20px;width:30%;vertical-align:middle"><img width=100% src="images/climb_horiz.jpg"></td>
            <td style="padding:20px;width:30%;vertical-align:middle"><img width=100% src="images/skydive.jpg"></td>
            <td style="padding:20px;width:30%;vertical-align:middle"><img width=100% src="images/bungy.jpg"></td>
          </tr> -->


              </tbody></table>
            </td>
          </tr>
        </table>

        <table width="100%" align="right" border="0" cellpadding="20"><tbody>
            <br>
            <br>
            <tr>
              <td style="text-align:center;font-size:15px">Website adapted from
                <a href="https://dz298.github.io/website/">Dingqi Zhang</a> and
                <a href="https://ashish-kmr.github.io">Ashish Kumar</a>
              </td>
            </tr>
        </tbody></table>

</body>
<script xml:space="preserve" language="JavaScript">
hideblock('RL1_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('RL2_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('RL3_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('backupplan_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('ARMPC_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('DIFFTUNE_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('cooling_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>

</html>
